{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3919a46b",
   "metadata": {},
   "source": [
    "# White Noise: Classic Supervised Machine Learning\n",
    "\n",
    "## 1. Explaining the Problem\n",
    "\n",
    "I must train a classifier on `labelled.csv`, a data set that contains 2200 bill summaries sampled from the 111th and 115th mandates of the US Congress - i.e., the House of Representatives, and the Senate - which are respectively the Obama presidency's first two years, in which the Democrats held both chambers (2008-10), and the Trump presidency's first two years, in which the Republicans held both chambers (2016-18). This classifier will aid me in automatically labelling the contents of the rest of the bill summaries (19620) retrieved from `api.congress.gov` as Economic / Non-Economic, or Socio-Cultural / Non-Socio-Cultural. I first wish to follow a \"classic\" Bag-Of-Words approach, and only subsequently turn to the state-of-the-art feature representation and modelling provided by BERT transformers, working on Google CoLab.\n",
    "\n",
    "The textual data has been pre-processed by removing HTML tags and character escapes. Lowercasing, special characters elimination, and punctuation removal, have been left to the `nltk` tokenizers integrated into the `sklearn` vectorizers. The labels are already tailored for the classification problem at hand, which involves identifying economic or socio-cultural content within the bill summaries. Consequently, I can proceed directly with extracting the bill summaries and labels and splitting them into suitable sets for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b05ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mattia aka\n",
      "[nltk_data]     Mario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# General packages for data handling and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Classic SML: Tokenization\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer, WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Classic SML: General\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Classic SML: Preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Classic SML: Train/test splits, cross validation, gridsearch\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    ")\n",
    "\n",
    "# Classic SML: Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# CLassic SML: Model evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28a200",
   "metadata": {},
   "source": [
    "## 2. Generating the Training, Validation, and Testing Dataset Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5211900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I start by importing the \"labelled.csv\" data set as a DataFrame object within the Python environment.\n",
    "# I crucially specify the \"|\" separator, because employing colons or semi-colons causes conflicts with the summaries' contents.\n",
    "\n",
    "d = pd.read_csv(\"labelled.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafa0647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>bill_number</th>\n",
       "      <th>bill_type</th>\n",
       "      <th>text</th>\n",
       "      <th>economic</th>\n",
       "      <th>socio_cultural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1308</td>\n",
       "      <td>hr</td>\n",
       "      <td>Frank and Jeanne Moore Wild Steelhead Speci...</td>\n",
       "      <td>Non-Economic</td>\n",
       "      <td>Socio-Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>4105</td>\n",
       "      <td>hr</td>\n",
       "      <td>This bill extends funding through FY2022 for...</td>\n",
       "      <td>Economic</td>\n",
       "      <td>Non-Socio-Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>3691</td>\n",
       "      <td>s</td>\n",
       "      <td>Expanding Transparency of Information and S...</td>\n",
       "      <td>Non-Economic</td>\n",
       "      <td>Socio-Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>1994</td>\n",
       "      <td>hr</td>\n",
       "      <td>Citizen Soldier Equality Act of 2009 - Requi...</td>\n",
       "      <td>Economic</td>\n",
       "      <td>Socio-Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>883</td>\n",
       "      <td>hr</td>\n",
       "      <td>Amends the Internal Revenue Code to repeal, e...</td>\n",
       "      <td>Economic</td>\n",
       "      <td>Socio-Cultural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress  bill_number bill_type  \\\n",
       "0       115         1308        hr   \n",
       "1       115         4105        hr   \n",
       "2       115         3691         s   \n",
       "3       111         1994        hr   \n",
       "4       111          883        hr   \n",
       "\n",
       "                                                text      economic  \\\n",
       "0     Frank and Jeanne Moore Wild Steelhead Speci...  Non-Economic   \n",
       "1    This bill extends funding through FY2022 for...      Economic   \n",
       "2     Expanding Transparency of Information and S...  Non-Economic   \n",
       "3    Citizen Soldier Equality Act of 2009 - Requi...      Economic   \n",
       "4   Amends the Internal Revenue Code to repeal, e...      Economic   \n",
       "\n",
       "       socio_cultural  \n",
       "0      Socio-Cultural  \n",
       "1  Non-Socio-Cultural  \n",
       "2      Socio-Cultural  \n",
       "3      Socio-Cultural  \n",
       "4      Socio-Cultural  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I check the first few lines of the DataFrame object to assess if the \"read_csv\" command worked smoothly\n",
    "\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf04cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I check the shape of the DataFrame object to assess if the \"read_csv\" command worked smoothly\n",
    "\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6df2f",
   "metadata": {},
   "source": [
    "2200 classified documents, six columns - i.e., the original four columns I retrieved from `api.congress.gov`, plus the two columns that contain the categories I manually annotated. Everything seems perfect! I can now transform the columns where I respectively stored the textual data - i.e. `text` - the economic labels - i.e., `economic` - and the socio-cultural labels - i.e., `socio_cultural` - in three separate lists, which I subsequently split into suitable sets for training, validation, and testing.\n",
    "\n",
    "The following cell's code is inspired by the official documentation for the `tolist()` `pandas` method, available at https://pandas.pydata.org/docs/reference/api/pandas.Series.tolist.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67473d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I unpack the columns of interest into three separate lists with the .tolist() pandas method.\n",
    "\n",
    "text = d[\"text\"].tolist() # Textual data\n",
    "economic = d[\"economic\"].tolist() # Economic labels\n",
    "socio_cultural = d[\"socio_cultural\"].tolist() # Socio-cultural labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40150c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   Frank and Jeanne Moore Wild Steelhead Special Management Area Designation Act      This bill designates approximately 99,653 acres of Forest Service land in Oregon as the  Frank and Jeanne Moore Wild Steelhead Special Management Area.  ',\n",
       " '  This bill extends funding through FY2022 for the Department of Health and Human Services to award grants to states and certain other entities for demonstration projects that address health-professions workforce needs.  ',\n",
       " '   Expanding Transparency of Information and Safeguarding Toxics (EtO is Toxic) Act of 2018    This bill updates requirements for chemicals that pose an adverse public health risk. Specifically, the bill requires the Environmental Protection Agency (EPA) to publish an updated National Air Toxics Assessment once every two years. The assessment uses emissions data to estimate health risks from toxic air pollutants.    The bill also requires the EPA to use data from its Integrated Risk Information System when conducting rulemaking with respect to chemicals that have been assessed in the system. For chemicals that are found to pose an adverse health risk, the EPA shall identify and do additional review on facilities that are significant sources of the chemical to determine whether the facility poses an adverse public health risk.   Under the bill, chemicals identified as carcinogenic in the system must have a toxic chemical release form completed by the owner or operator of a facility.   The bill requires the Department of Health and Human Services (HHS) to consult with appropriate EPA offices regarding the future schedule of assessments of chemicals to be conducted under the system, the results or existing assessments, and concerns that may merit additional review. HHS must also administer personal exposure tests for chemicals that pose a new adverse public health risk to vulnerable populations, such as children. HHS must establish a Community Outreach Division to communicate risk assessments to affected communities. ',\n",
       " '  Citizen Soldier Equality Act of 2009 - Requires that, in the case of a member of the reserves who is retired or placed on the temporary disability retired list because of an incurred disability for which the member is awarded the Purple Heart, the member shall be credited with the number of years of service that would be counted under the computation of years of service for retired pay for non-regular service. ',\n",
       " ' Amends the Internal Revenue Code to repeal, effective January 1, 2009, the 1993 increase in income taxes on Social Security benefits.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I check the first 5 elements and overall lengths of the three lists to assess whether this data wrangling step went smoothly.\n",
    "\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2875999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The textual data list's total length is 2200.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The textual data list's total length is {len(text)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73fa8875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Non-Economic', 'Economic', 'Non-Economic', 'Economic', 'Economic']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economic[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ed21e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The economic label list's total length is 2200.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The economic label list's total length is {len(economic)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58822e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Socio-Cultural',\n",
       " 'Non-Socio-Cultural',\n",
       " 'Socio-Cultural',\n",
       " 'Socio-Cultural',\n",
       " 'Socio-Cultural']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socio_cultural[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cca546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The socio-cultural label list's total length is 2200.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The socio-cultural label list's total length is {len(socio_cultural)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23addbea",
   "metadata": {},
   "source": [
    "All data was correctly dumped into separate lists. Now, I proceed to split them into suitable sets for training, validation, and testing with the `sklearn` `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe89280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set a given random seed to make my work reproducible. For the record, the 27th of August is my birthday.\n",
    "my_seed = 27\n",
    "\n",
    "# Running the train vs test split with the standard 80% vs 20% ratio.\n",
    "text_train, text_test, econ_train, econ_test, sc_train, sc_test = train_test_split(\n",
    "    text, economic, socio_cultural, test_size = 0.2, random_state = my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8e4f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text sets have 1760 training instances and 440 testing instances.\n"
     ]
    }
   ],
   "source": [
    "# Checking whether this splitting step went smoothly for the bill summaries...\n",
    "print(f\"The text sets have {len(text_train)} training instances and {len(text_test)} testing instances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "999b6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The economic label sets have 1760 training instances and 440 testing instances.\n",
      "The socio-cultural label sets have 1760 training instances and 440 testing instances.\n"
     ]
    }
   ],
   "source": [
    "# ...and for their labels.\n",
    "print(f\"The economic label sets have {len(econ_train)} training instances and {len(econ_test)} testing instances.\")\n",
    "print(f\"The socio-cultural label sets have {len(sc_train)} training instances and {len(sc_test)} testing instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d3ecc",
   "metadata": {},
   "source": [
    "I further split the remaining data into training and validation sets. This time, I apply a 75% versus 25% split ratio, saving one fourth of the bill summaries and relative labels for validation purposes, because I want the number of instances for validation and testing to be as close as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91fd2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the train vs validate split with a 75% vs 25% ratio.\n",
    "text_train, text_valid, econ_train, econ_valid, sc_train, sc_valid = train_test_split(\n",
    "    text_train, econ_train, sc_train, test_size = 0.25, random_state = my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d4d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text sets have 1320 training instances and 440 validation instances.\n"
     ]
    }
   ],
   "source": [
    "# Checking whether this splitting step went smoothly for the bill summaries...\n",
    "print(f\"The text sets have {len(text_train)} training instances and {len(text_valid)} validation instances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1fcf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The economic label sets have 1320 training instances and 440 validation instances.\n",
      "The socio-cultural label sets have 1320 training instances and 440 validation instances.\n"
     ]
    }
   ],
   "source": [
    "# ...and for their labels.\n",
    "print(f\"The economic label sets have {len(econ_train)} training instances and {len(econ_valid)} validation instances.\")\n",
    "print(f\"The socio-cultural label sets have {len(sc_train)} training instances and {len(sc_valid)} validation instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2fe38",
   "metadata": {},
   "source": [
    "## 3. Finding the Best Classifiers\n",
    "\n",
    "Codes and best practices for sections from `3.` to `5.` are inspired by Chapters 8, 10, and 11 of van Atteveldt, Trilling, and Arcila Calderón's *Computational Analysis of Communication* (2022).\n",
    "\n",
    "Now, I want to adopt a classic SML approach and find the best vectorizer + classifier combinations by employing several pipelines, before eventually hyperparameter tuning the most optimal configurations. I already partly pre-processed the textual data, removing HTML boilerplates - i.e., character escapes and tags. The built-in default tokenizers for `CountVectorizer` and `TfIdfVectorizer` will handle the remaining special characters, remove punctuation, apply lowercasing, and eliminate whitespaces, to achieve higher consistency in the textual data, and prepare it for the Bag-Of-Words (BOW) transformation\n",
    "\n",
    "In terms of vectorizers, I evaluate `CountVectorizers` against `TfIdfVectorizers`. The former represents unique features with raw word counts, while the latter applies a weighting formula that allows rarer features to acquire more importance in the classification task. Relatively rare terms such as \"Hezbollah\" - i.e., a Lebanese Shia Islamist political party and militant group that is deemed to be a terrorist group by the USA - which for instance appears in four documents only, are *really* strong indicators of a Socio-Cultural bill summary, because terrorism is a remarkably prominent socio-cultural issue in American politics, so I expect `TfIdfVectorizers` to achieve superior performance.\n",
    "\n",
    "All vectorizers are set to prune words that appear in more than 75% of the summaries. This makes the default `nltk` English stopwords list redundant, as it follows the same logic in factoring out extremely frequent words. Moreover, I do not impose any lower limit in pruning, since some summaries are very short and contain unique, yet very informative words. For example, Bill number 187 of the 115th Senate: \"Provides for the relief of Alemseghed Mussie Tesfamical\". This piece of legislation establishes that Alemseghed Mussie Tesfamical, a former soldier from Eritrea, is eligible for the issuance of an immigrant visa or being admitted for permanent residence, to avoid his deportation back to his home country. By excluding the words \"Alemseghed\", \"Mussie\", and \"Tesfamical\", I would likely retain only two words: \"Provides\", and \"relief\". This could make the classification task quite challenging for the computer. Therefore, I set the `min_df` parameter to 0. These thresolds are effectively utilised as baselines, and they will be subjected to further modifications when I will fine-tune hyperparameters for the best classifiers, following a less theory- and more data-driven approach.\n",
    "\n",
    "Turning to classifiers, I assess several models:\n",
    "1. The Multinomial Naive-Bayes Classifier;\n",
    "2. The Logistic Regression Classifier, with the `liblinear` solver;\n",
    "3. The Support Vector Machine Classifier, with the `linear` kernel trick;\n",
    "4. The Support Vector Machine Classifier, with the `rbf` kernel trick;\n",
    "5. The Random Forest Classifier, with 100, 500, and 1000 estimators.\n",
    "\n",
    "I include the Multinomial Naive-Bayes as a baseline model. The Logistic Regression with the linear solver is my potential golden standard, since it usually fares really well in analogous classification tasks. I also test SVMs with two different kernel tricks because minimizing hinge loss instead of logistic loss might lead to superior performances if the Logistic Regression yields unsatisfactory results. On a final note, I must explicit an important observation on Random Forest classifiers. I have no expectations regarding the form of the relationship among my BOW summary features and the Economic / Non-Economic, and Socio-Cultural / Non-Socio-Cultural labels. Therefore, I wish to assess whether non-linear decision trees yield better approximations of such associations. I test for the decision process' complexity by specifying an increasing number of estimators. For each test run, I choose the best model, which I will fine-tune later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d360c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB with Count\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.79      0.85      0.82       250\n",
      "Non-Economic       0.78      0.71      0.75       190\n",
      "\n",
      "    accuracy                           0.79       440\n",
      "   macro avg       0.79      0.78      0.78       440\n",
      "weighted avg       0.79      0.79      0.79       440\n",
      "\n",
      "\n",
      "\n",
      "NB with TfIdf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.67      0.98      0.80       250\n",
      "Non-Economic       0.92      0.38      0.54       190\n",
      "\n",
      "    accuracy                           0.72       440\n",
      "   macro avg       0.80      0.68      0.67       440\n",
      "weighted avg       0.78      0.72      0.69       440\n",
      "\n",
      "\n",
      "\n",
      "LogReg with Count\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.78      0.80      0.79       250\n",
      "Non-Economic       0.73      0.71      0.72       190\n",
      "\n",
      "    accuracy                           0.76       440\n",
      "   macro avg       0.76      0.75      0.76       440\n",
      "weighted avg       0.76      0.76      0.76       440\n",
      "\n",
      "\n",
      "\n",
      "LogReg with TfIdf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.78      0.90      0.84       250\n",
      "Non-Economic       0.84      0.67      0.75       190\n",
      "\n",
      "    accuracy                           0.80       440\n",
      "   macro avg       0.81      0.79      0.79       440\n",
      "weighted avg       0.81      0.80      0.80       440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a. Economic / Non-economic\n",
    "\n",
    "# 1a. Multinomial Naive-Bayes\n",
    "# +\n",
    "# 2a. Logistic Regression (\"liblinear\")\n",
    "\n",
    "configs = [ # Saving all the vectorizer + classifier configurations of interest\n",
    "    (\"NB with Count\", CountVectorizer(min_df = 0, max_df = .75), MultinomialNB()),\n",
    "    (\"NB with TfIdf\", TfidfVectorizer(min_df = 0, max_df = .75), MultinomialNB()),\n",
    "    \n",
    "    (\"LogReg with Count\", CountVectorizer(min_df = 0, max_df = .75),\n",
    "     LogisticRegression(solver = \"liblinear\")),\n",
    "    \n",
    "    (\"LogReg with TfIdf\", TfidfVectorizer(min_df = 0, max_df =.75),\n",
    "     LogisticRegression(solver = \"liblinear\")),\n",
    "]\n",
    "\n",
    "# Instead of fitting the vectorizer and classifier separately, I combine them in a pipeline!\n",
    "\n",
    "# I loop over all the desired configurations in 'configs'.\n",
    "for name, vectorizer, classifier in configs: \n",
    "    print(name) # I print the given name of the classifier-vectorizer combination.\n",
    "    \n",
    "    pipe = make_pipeline(vectorizer, classifier) # I make a pipeline that combines the given vectorizer and classifier.\n",
    "    pipe.fit(text_train, econ_train) # I fit the training data on the pipeline.\n",
    "    \n",
    "    econ_pred = pipe.predict(text_valid) # I predict the labels from the text database I set aside for validation.\n",
    "    \n",
    "    # I print a classification report for the predicted values against the true labels from the validation database.\n",
    "    print(metrics.classification_report(econ_valid, econ_pred))\n",
    "    \n",
    "    # I add a new line for pretty printing.\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fd24e",
   "metadata": {},
   "source": [
    "The most promising model appears to be the **Naive-Bayes classifier with the `CountVectorizer`**. It does not achieve the highest accuracy of this test run (0.79), but it maintains consistently great figures for both categories, except the relatively low recall for the Non-Economic label (0.71). This seems to be the Achilles' Heel of all this test run's vectorizer + classifier combinations, as the very best model, the **Logistic Regression classifier with the `liblinear` solver and the `TfIdfVectorizer`**, which shows the highest overall accuracy (0.90), and great precision for the \"Economic\" class (0.84), suffers from the same shortcoming - i.e., an even more problematic score of only 0.67 for the Non-Economic category's recall metric.\n",
    "\n",
    "In general, this could be a critical issue when automatically labelling the rest of the summaries, because it appears that all models tend to artificially inflate the number of bill summaries annotated as \"Economic\". Therefore, it is crucial that the fine-tuned classifiers exhibit a solid performance all across the board, and that is why I deem the **Naive-Bayes classifier with the `CountVectorizer`** to potentially have the brightest outlook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "556a57fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Count - linear kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.75      0.76      0.76       250\n",
      "Non-Economic       0.68      0.67      0.68       190\n",
      "\n",
      "    accuracy                           0.72       440\n",
      "   macro avg       0.72      0.72      0.72       440\n",
      "weighted avg       0.72      0.72      0.72       440\n",
      "\n",
      "\n",
      "\n",
      "SVM with Count - rbf kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.73      0.84      0.78       250\n",
      "Non-Economic       0.74      0.58      0.65       190\n",
      "\n",
      "    accuracy                           0.73       440\n",
      "   macro avg       0.73      0.71      0.72       440\n",
      "weighted avg       0.73      0.73      0.72       440\n",
      "\n",
      "\n",
      "\n",
      "SVM with Tfidf - linear kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.81      0.84      0.83       250\n",
      "Non-Economic       0.78      0.74      0.76       190\n",
      "\n",
      "    accuracy                           0.80       440\n",
      "   macro avg       0.79      0.79      0.79       440\n",
      "weighted avg       0.80      0.80      0.80       440\n",
      "\n",
      "\n",
      "\n",
      "SVM with Tfidf - rbf kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.80      0.88      0.84       250\n",
      "Non-Economic       0.82      0.72      0.77       190\n",
      "\n",
      "    accuracy                           0.81       440\n",
      "   macro avg       0.81      0.80      0.80       440\n",
      "weighted avg       0.81      0.81      0.81       440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3a. Support Vector Machine (\"linear\")\n",
    "# +\n",
    "# 4a. Support Vector Machine (\"rbf\")\n",
    "\n",
    "configs = [ # Saving all the vectorizer + classifier configurations of interest\n",
    "    (\"SVM with Count - linear kernel\", CountVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"linear\")),\n",
    "    \n",
    "    (\"SVM with Count - rbf kernel\", CountVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"rbf\")),\n",
    "    \n",
    "    (\"SVM with Tfidf - linear kernel\", TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"linear\")),\n",
    "    \n",
    "    (\"SVM with Tfidf - rbf kernel\", TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"rbf\")),\n",
    "]\n",
    "\n",
    "# Instead of fitting the vectorizer and classifier separately, I combine them in a pipeline!\n",
    "\n",
    "# I loop over all the desired configurations in 'configs'.\n",
    "for name, vectorizer, classifier in configs:\n",
    "    \n",
    "    # I print the given name of the classifier-vectorizer combination.\n",
    "    print(name)\n",
    "    \n",
    "    pipe = make_pipeline(vectorizer, classifier) # I make a pipeline that combines the given vectorizer and classifier.\n",
    "    pipe.fit(text_train, econ_train) # I fit the training data on the pipeline.\n",
    "    \n",
    "    econ_pred = pipe.predict(text_valid) # I predict the labels from the text database I set aside for validation.\n",
    "    \n",
    "    # I print a classification report for the predicted values against the true labels from the validation database.\n",
    "    print(metrics.classification_report(econ_valid, econ_pred))\n",
    "    \n",
    "    # I add a new line for pretty printing.\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966da58",
   "metadata": {},
   "source": [
    "When utilising a `TfIdfVectorizer`, it seems that substituting the logistic loss with the hinge loss minimisation problem does help the classifiers' performance. **SVM classifiers combined with the `TfIdfVectorizer`**, regardless of the kernel trick I employ, are the best solutions for this run. The **SVM classifier with the `rbf` kernel trick** exhibits the highest overall accuracy (0.81), but the **SVM classifier with the `linear` kernel trick** has a better recall for the Non-Economic category - i.e., 0.74, against the 0.72 value shown by the **SVM classifier with the `rbf` kernel trick**. This means that the former model has a lower likelihood of artificially inflating the general count of bill summaries classified as Economic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11dfc59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF with Count - 100 estimators\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.77      0.82      0.79       250\n",
      "Non-Economic       0.74      0.67      0.70       190\n",
      "\n",
      "    accuracy                           0.76       440\n",
      "   macro avg       0.75      0.75      0.75       440\n",
      "weighted avg       0.76      0.76      0.75       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Tfidf - 100 estimators\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.75      0.86      0.80       250\n",
      "Non-Economic       0.77      0.62      0.68       190\n",
      "\n",
      "    accuracy                           0.75       440\n",
      "   macro avg       0.76      0.74      0.74       440\n",
      "weighted avg       0.76      0.75      0.75       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Count - 500 estimators\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.77      0.84      0.80       250\n",
      "Non-Economic       0.76      0.67      0.71       190\n",
      "\n",
      "    accuracy                           0.76       440\n",
      "   macro avg       0.76      0.75      0.76       440\n",
      "weighted avg       0.76      0.76      0.76       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Tfidf - 500 estimators\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.79      0.84      0.82       250\n",
      "Non-Economic       0.78      0.71      0.74       190\n",
      "\n",
      "    accuracy                           0.79       440\n",
      "   macro avg       0.78      0.78      0.78       440\n",
      "weighted avg       0.79      0.79      0.78       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Count - 1000 estimators\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.76      0.83      0.80       250\n",
      "Non-Economic       0.75      0.66      0.70       190\n",
      "\n",
      "    accuracy                           0.76       440\n",
      "   macro avg       0.76      0.74      0.75       440\n",
      "weighted avg       0.76      0.76      0.75       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Tfidf - 1000 estimators\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.79      0.83      0.81       250\n",
      "Non-Economic       0.76      0.71      0.73       190\n",
      "\n",
      "    accuracy                           0.78       440\n",
      "   macro avg       0.77      0.77      0.77       440\n",
      "weighted avg       0.78      0.78      0.78       440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5a. Random Forests\n",
    "\n",
    "configs = [ # Saving all the vectorizer + classifier configurations of interest\n",
    "    ('RF with Count - 100 estimators', CountVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 100)),\n",
    "    \n",
    "    ('RF with Tfidf - 100 estimators', TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 100)),\n",
    "    \n",
    "    ('RF with Count - 500 estimators', CountVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 500)),\n",
    "    \n",
    "    ('RF with Tfidf - 500 estimators', TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 500)),\n",
    "    \n",
    "    ('RF with Count - 1000 estimators', CountVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 1000)),\n",
    "    \n",
    "    ('RF with Tfidf - 1000 estimators', TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 1000)),\n",
    "]\n",
    "\n",
    "# Instead of fitting the vectorizer and classifier separately, I combine them in a pipeline!\n",
    "\n",
    "# I loop over all the desired configurations in 'configs'.\n",
    "for name, vectorizer, classifier in configs:\n",
    "    \n",
    "    # I print the given name of the classifier-vectorizer combination.\n",
    "    print(name)\n",
    "    \n",
    "    pipe = make_pipeline(vectorizer, classifier) # I make a pipeline that combines vectorizer and classifier.\n",
    "    pipe.fit(text_train, econ_train) # I fit the training data on the pipeline.\n",
    "    \n",
    "    econ_pred = pipe.predict(text_valid) # I predict the labels from the text database I set aside for validation.\n",
    "    \n",
    "    # I print a classification report for the predicted values against the true labels from the validation database.\n",
    "    print(metrics.classification_report(econ_valid, econ_pred))\n",
    "    \n",
    "    # I add a new line for pretty printing.\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b74e5",
   "metadata": {},
   "source": [
    "Random Forest Classifiers do not fare well relatively to their added computational complexity. The **Random Forest classifier with 500 estimators and the `TfIdfVectorizer`** shows the best performance of the test run, due to its overall accuracy (0.79) and acceptable recall (0.71) for the Non-Economic category. However, since its metrics are almost identical to the baseline model's - i.e., the **Naive-Bayes classifier with the `CountVectorizer`** - I determine that the non-existent improvement is not worth the remarkable time and effort required for hyperparameter tuning a Random Forest Classifier with 500 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afdfefb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB with Count\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.80      0.72      0.76       178\n",
      "    Socio-Cultural       0.82      0.88      0.85       262\n",
      "\n",
      "          accuracy                           0.81       440\n",
      "         macro avg       0.81      0.80      0.80       440\n",
      "      weighted avg       0.81      0.81      0.81       440\n",
      "\n",
      "\n",
      "\n",
      "NB with TfIdf\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.96      0.27      0.42       178\n",
      "    Socio-Cultural       0.67      0.99      0.80       262\n",
      "\n",
      "          accuracy                           0.70       440\n",
      "         macro avg       0.81      0.63      0.61       440\n",
      "      weighted avg       0.79      0.70      0.65       440\n",
      "\n",
      "\n",
      "\n",
      "LogReg with Count\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.70      0.60      0.64       178\n",
      "    Socio-Cultural       0.75      0.83      0.79       262\n",
      "\n",
      "          accuracy                           0.73       440\n",
      "         macro avg       0.73      0.71      0.72       440\n",
      "      weighted avg       0.73      0.73      0.73       440\n",
      "\n",
      "\n",
      "\n",
      "LogReg with TfIdf\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.86      0.48      0.61       178\n",
      "    Socio-Cultural       0.73      0.95      0.82       262\n",
      "\n",
      "          accuracy                           0.76       440\n",
      "         macro avg       0.79      0.71      0.72       440\n",
      "      weighted avg       0.78      0.76      0.74       440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# b. Socio-Cultural / Non-Socio-Cultural\n",
    "\n",
    "# 1b. Multinomial Naive-Bayes\n",
    "# +\n",
    "# 2b. Logistic Regression (\"liblinear\")\n",
    "\n",
    "configs = [ # Saving all the vectorizer + classifier configurations of interest\n",
    "    (\"NB with Count\", CountVectorizer(min_df = 0, max_df = .75), MultinomialNB()),\n",
    "    (\"NB with TfIdf\", TfidfVectorizer(min_df = 0, max_df = .75), MultinomialNB()),\n",
    "    \n",
    "    (\"LogReg with Count\", CountVectorizer(min_df = 0, max_df = .75),\n",
    "     LogisticRegression(solver = \"liblinear\")),\n",
    "    \n",
    "    (\"LogReg with TfIdf\", TfidfVectorizer(min_df = 0, max_df =.75),\n",
    "     LogisticRegression(solver = \"liblinear\")),\n",
    "]\n",
    "\n",
    "# Instead of fitting the vectorizer and classifier separately, I combine them in a pipeline!\n",
    "\n",
    "# I loop over all the desired configurations in 'configs'.\n",
    "for name, vectorizer, classifier in configs: \n",
    "    print(name) # I print the given name of the classifier-vectorizer combination.\n",
    "    \n",
    "    pipe = make_pipeline(vectorizer, classifier) # I make a pipeline that combines the given vectorizer and classifier.\n",
    "    pipe.fit(text_train, sc_train) # I fit the training data on the pipeline.\n",
    "    \n",
    "    sc_pred = pipe.predict(text_valid) # I predict the labels from the text database I set aside for validation.\n",
    "    \n",
    "    # I print a classification report for the predicted values against the true labels from the validation database.\n",
    "    print(metrics.classification_report(sc_valid, sc_pred))\n",
    "    \n",
    "    # I add a new line for pretty printing.\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03438d",
   "metadata": {},
   "source": [
    "The best model of this test run is clearly the **Naive-Bayes classifier with the `CountVectorizer`**. Not only it is the one with the highest accuracy (0.81), but it is the only model to exhibit an acceptable recall for the Non-Socio-Cultural category. All other options show a marked tendency of artificially inflating the number of bill summaries presumed to express visions regarding socio-cultural issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19871873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Count - linear kernel\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.70      0.63      0.66       178\n",
      "    Socio-Cultural       0.76      0.82      0.79       262\n",
      "\n",
      "          accuracy                           0.74       440\n",
      "         macro avg       0.73      0.72      0.73       440\n",
      "      weighted avg       0.74      0.74      0.74       440\n",
      "\n",
      "\n",
      "\n",
      "SVM with Count - rbf kernel\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.82      0.42      0.55       178\n",
      "    Socio-Cultural       0.70      0.94      0.80       262\n",
      "\n",
      "          accuracy                           0.73       440\n",
      "         macro avg       0.76      0.68      0.68       440\n",
      "      weighted avg       0.75      0.73      0.70       440\n",
      "\n",
      "\n",
      "\n",
      "SVM with Tfidf - linear kernel\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.80      0.62      0.70       178\n",
      "    Socio-Cultural       0.77      0.89      0.83       262\n",
      "\n",
      "          accuracy                           0.78       440\n",
      "         macro avg       0.79      0.76      0.76       440\n",
      "      weighted avg       0.78      0.78      0.78       440\n",
      "\n",
      "\n",
      "\n",
      "SVM with Tfidf - rbf kernel\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.87      0.51      0.64       178\n",
      "    Socio-Cultural       0.74      0.95      0.83       262\n",
      "\n",
      "          accuracy                           0.77       440\n",
      "         macro avg       0.81      0.73      0.74       440\n",
      "      weighted avg       0.79      0.77      0.75       440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3b. Support Vector Machine (\"linear\")\n",
    "# +\n",
    "# 4b. Support Vector Machine (\"rbf\")\n",
    "\n",
    "configs = [ # Saving all the vectorizer + classifier configurations of interest\n",
    "    (\"SVM with Count - linear kernel\", CountVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"linear\")),\n",
    "    \n",
    "    (\"SVM with Count - rbf kernel\", CountVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"rbf\")),\n",
    "    \n",
    "    (\"SVM with Tfidf - linear kernel\", TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"linear\")),\n",
    "    \n",
    "    (\"SVM with Tfidf - rbf kernel\", TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     SVC(kernel = \"rbf\")),\n",
    "]\n",
    "\n",
    "# Instead of fitting the vectorizer and classifier separately, I combine them in a pipeline!\n",
    "\n",
    "# I loop over all the desired configurations in 'configs'.\n",
    "for name, vectorizer, classifier in configs:\n",
    "    \n",
    "    # I print the given name of the classifier-vectorizer combination.\n",
    "    print(name)\n",
    "    \n",
    "    pipe = make_pipeline(vectorizer, classifier) # I make a pipeline that combines the given vectorizer and classifier.\n",
    "    pipe.fit(text_train, sc_train) # I fit the training data on the pipeline.\n",
    "    \n",
    "    sc_pred = pipe.predict(text_valid) # I predict the labels from the text database I set aside for validation.\n",
    "    \n",
    "    # I print a classification report for the predicted values against the true labels from the validation database.\n",
    "    print(metrics.classification_report(sc_valid, sc_pred))\n",
    "    \n",
    "    # I add a new line for pretty printing.\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83470907",
   "metadata": {},
   "source": [
    "Despite the Logistic Regression classifiers' performances being way poorer than the baseline, substituting the logistic loss with the hinge loss minimisation problem does not help much. Nevertheless, the **SVM classifier with the `liblinear` solver and the `TfIdfVectorizer`** appears to be the best solution within this this test run, as it is the only one to maintain an accuracy comparable to the baseline (0.78). Furthermore, despite its weakness in achieving a low recall (0.62) for the Non-Socio-Cultural category, indicating (again) a tendency to artificially inflate the number of bill summaries assumed to express political beliefs on socio-cultural issues, it demonstrates the highest F1-score (0.70) for that particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "202b46de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF with Count - 100 estimators\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.81      0.47      0.60       178\n",
      "    Socio-Cultural       0.72      0.92      0.81       262\n",
      "\n",
      "          accuracy                           0.74       440\n",
      "         macro avg       0.76      0.70      0.70       440\n",
      "      weighted avg       0.76      0.74      0.72       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Tfidf - 100 estimators\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.81      0.44      0.57       178\n",
      "    Socio-Cultural       0.71      0.93      0.81       262\n",
      "\n",
      "          accuracy                           0.73       440\n",
      "         macro avg       0.76      0.69      0.69       440\n",
      "      weighted avg       0.75      0.73      0.71       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Count - 500 estimators\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.80      0.43      0.56       178\n",
      "    Socio-Cultural       0.70      0.93      0.80       262\n",
      "\n",
      "          accuracy                           0.73       440\n",
      "         macro avg       0.75      0.68      0.68       440\n",
      "      weighted avg       0.74      0.72      0.70       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Tfidf - 500 estimators\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.83      0.42      0.56       178\n",
      "    Socio-Cultural       0.71      0.94      0.81       262\n",
      "\n",
      "          accuracy                           0.73       440\n",
      "         macro avg       0.77      0.68      0.68       440\n",
      "      weighted avg       0.76      0.73      0.71       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Count - 1000 estimators\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.82      0.46      0.58       178\n",
      "    Socio-Cultural       0.72      0.93      0.81       262\n",
      "\n",
      "          accuracy                           0.74       440\n",
      "         macro avg       0.77      0.69      0.70       440\n",
      "      weighted avg       0.76      0.74      0.72       440\n",
      "\n",
      "\n",
      "\n",
      "RF with Tfidf - 1000 estimators\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.86      0.40      0.54       178\n",
      "    Socio-Cultural       0.70      0.95      0.81       262\n",
      "\n",
      "          accuracy                           0.73       440\n",
      "         macro avg       0.78      0.68      0.68       440\n",
      "      weighted avg       0.76      0.73      0.70       440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5b. Random Forests\n",
    "\n",
    "configs = [ # Saving all the vectorizer + classifier configurations of interest\n",
    "    ('RF with Count - 100 estimators', CountVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 100)),\n",
    "    \n",
    "    ('RF with Tfidf - 100 estimators', TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 100)),\n",
    "    \n",
    "    ('RF with Count - 500 estimators', CountVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 500)),\n",
    "    \n",
    "    ('RF with Tfidf - 500 estimators', TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 500)),\n",
    "    \n",
    "    ('RF with Count - 1000 estimators', CountVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 1000)),\n",
    "    \n",
    "    ('RF with Tfidf - 1000 estimators', TfidfVectorizer(min_df = 0, max_df = .75),\n",
    "     RandomForestClassifier(n_estimators = 1000)),\n",
    "]\n",
    "\n",
    "# Instead of fitting the vectorizer and classifier separately, I combine them in a pipeline!\n",
    "\n",
    "# I loop over all the desired configurations in 'configs'.\n",
    "for name, vectorizer, classifier in configs:\n",
    "    \n",
    "    # I print the given name of the classifier-vectorizer combination.\n",
    "    print(name)\n",
    "    \n",
    "    pipe = make_pipeline(vectorizer, classifier) # I make a pipeline that combines vectorizer and classifier.\n",
    "    pipe.fit(text_train, sc_train) # I fit the training data on the pipeline.\n",
    "    \n",
    "    sc_pred = pipe.predict(text_valid) # I predict the labels from the text database I set aside for validation.\n",
    "    \n",
    "    # I print a classification report for the predicted values against the true labels from the validation database.\n",
    "    print(metrics.classification_report(sc_valid, sc_pred))\n",
    "    \n",
    "    # I add a new line for pretty printing.\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f3e58",
   "metadata": {},
   "source": [
    "All Random Forest Classifiers exhibit dismal performances. Their recall metrics for the Non-Socio-Cultural category are all equal to or lower than 0.45, meaning that they would certainly skew my analysis by coding an overwhelming number of bill summaries as concerning socio-cultural issues. Thus, no model is selected from this test run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81c301",
   "metadata": {},
   "source": [
    "## 4. Fine-Tuning the Best Hyperparameters\n",
    "\n",
    "Focusing on the Economic / Non-Economic classification task, I am left with four models to fine-tune and compare:\n",
    "1. The Naive-Bayes classifier with the `CountVectorizer`;\n",
    "2. The Logistic Regression classifier with the `liblinear` solver and the `TfIdfVectorizer`;\n",
    "3. The SVM classifier with the `linear` kernel trick and the `TfIdfVectorizer`;\n",
    "4. The SVM classifier with the `rbf` kernel trick and the `TfIdfVectorizer`.\n",
    "\n",
    "Turning to the Socio-Cultural / Non-Socio-Cultural classification task, I wish to fine-tune and compare only two models:\n",
    "1. The Naive-Bayes classifier with the `CountVectorizer`;\n",
    "2. The SVM classifier with the `linear` kernel trick and the `TfIdfVectorizer`.\n",
    "\n",
    "I wish to optimize the models' macro-F1 score, which is an appropriate evaluation metric because class imbalance seems to be critical problem for both classification tasks. Specifically, all models show at least some tendency of inflating the number of positive labels. I will search for the best vectorizer parameters in terms of:\n",
    "- Allowing for bi-grams or tri-grams. While remaining in a co-occurrence analysis framework, I believe these could bring a performance gain as the concepts that guided my manual annotation are latent and abstract - and thus context-dependent - concepts by constituting unique couples or triplets of words.\n",
    "- Including  the default `nltk` English stopwords list or not, as I may have overlooked potential advantages of the stopwords removal approach.\n",
    "- Setting lower or higher inferior and superior thresholds for pruning. This step is almost purely data-driven, but I do expect the optimal lower threshold to be zero since some summaries are very short and contain unique, yet very informative words.\n",
    "\n",
    "On the other hand, I will search for the best classifier parameters in terms of:\n",
    "- Regularisation parameters (`C`), for the Logistic Regression and SVM models.\n",
    "- The additive smoothing parameter (`alpha`), for the Naive-Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a6638cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I first save the default nltk English stopwords list in the \"stop_word\" object\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09e11031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Economic / Non-economic\n",
    "\n",
    "# 1a. Naive-Bayes classifier with CountVectorizer\n",
    "\n",
    "pipeline = Pipeline( # Constructing a pipeline comprised of two steps.\n",
    "    steps = [\n",
    "        (\"vectorizer\", CountVectorizer()), # A CountVectorizer, without any previously specified parameters.\n",
    "        (\"classifier\", MultinomialNB()), # A Multinomial Naive-Bayes, without any previously specified parameters.\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = { # In the gridsearch I want to search for...\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)], # Whether I want to allow for bigrams or tri-grams.\n",
    "    \"vectorizer__stop_words\": [None, stop_words], # Whether I want to remove English stopwords or not.\n",
    "    \"vectorizer__max_df\": [0.5, 0.75], # Different cutoffs for the maximum... \n",
    "    \"vectorizer__min_df\": [0, 5, 10], # and minimum thresholds for pruning.\n",
    "    \"classifier__alpha\": [0.01, 1, 10, 100], # The most optimal alpha for the Naive-Bayes\n",
    "}\n",
    "\n",
    "# I run a gridsearch with the standard 5 k-folds, maximising the macro-F1 score since class imbalances are critical within\n",
    "# this classification task.\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = pipeline, n_jobs = -1, param_grid = grid, scoring = \"f1_macro\", cv = 5, verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbfaf9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__alpha&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__alpha&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__alpha': [0.01, 1, 10, 100],\n",
       "                         'vectorizer__max_df': [0.5, 0.75],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__stop_words': [None,\n",
       "                                                    ['i', 'me', 'my', 'myself',\n",
       "                                                     'we', 'our', 'ours',\n",
       "                                                     'ourselves', 'you',\n",
       "                                                     \"you're\", \"you've\",\n",
       "                                                     \"you'll\", \"you'd\", 'your',\n",
       "                                                     'yours', 'yourself',\n",
       "                                                     'yourselves', 'he', 'him',\n",
       "                                                     'his', 'himself', 'she',\n",
       "                                                     \"she's\", 'her', 'hers',\n",
       "                                                     'herself', 'it', \"it's\",\n",
       "                                                     'its', 'itself', ...]]},\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(text_train, econ_train) # I run the gridsearch on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b37d713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__alpha': 0.01, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\") # I print the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc3414f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(text_valid) # I make my predictions with the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6286795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.80      0.83      0.81       250\n",
      "Non-Economic       0.76      0.73      0.75       190\n",
      "\n",
      "    accuracy                           0.79       440\n",
      "   macro avg       0.78      0.78      0.78       440\n",
      "weighted avg       0.79      0.79      0.79       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I print a classification report for the predicted values against the true labels from the validation set.\n",
    "print(metrics.classification_report(econ_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9774193",
   "metadata": {},
   "source": [
    "By fine-tuning the Naive-Bayes baseline, I achieve small, yet satisfactory trade-offs between precision and recall for both categories. Most importantly, recall for the Non-Economic class is raised from 0.71 to 0.73, at the cost of a decrease in precision, which goes from 0.78 to 0.76. The overall accuracy remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d19e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Logistic Regression classifier with TfIdf Vectorizer\n",
    "\n",
    "pipeline = Pipeline( # Constructing a pipeline comprised of two steps.\n",
    "    steps = [\n",
    "        (\"vectorizer\", TfidfVectorizer()), # A TfidfVectorizer, without any previously specified parameters.\n",
    "        (\"classifier\", LogisticRegression(solver = \"liblinear\")), # A Logistic Regression, with the \"liblinear\" solver.\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = { # In the gridsearch I want to search for...\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)], # Whether I want to allow for bigrams or tri-grams.\n",
    "    \"vectorizer__stop_words\": [None, stop_words], # Whether I want to remove stopwords or not.\n",
    "    \"vectorizer__max_df\": [0.5, 0.75], # Different cutoffs for the maximum... \n",
    "    \"vectorizer__min_df\": [0, 5, 10], # and minimum thresholds for pruning.\n",
    "    \"classifier__C\": [0.01, 1, 10, 100], # The most optimal regularisation parameter for the Logistic Regression.\n",
    "}\n",
    "\n",
    "# I run a gridsearch with the standard 5 k-folds, maximising the macro-F1 score since class imbalances are critical within\n",
    "# this classification task.\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = pipeline, n_jobs = -1, param_grid = grid, scoring = \"f1_macro\", cv = 5, verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "135785e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': [0.01, 1, 10, 100],\n",
       "                         'vectorizer__max_df': [0.5, 0.75],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__stop_words': [None,\n",
       "                                                    ['i', 'me', 'my', 'myself',\n",
       "                                                     'we', 'our', 'ours',\n",
       "                                                     'ourselves', 'you',\n",
       "                                                     \"you're\", \"you've\",\n",
       "                                                     \"you'll\", \"you'd\", 'your',\n",
       "                                                     'yours', 'yourself',\n",
       "                                                     'yourselves', 'he', 'him',\n",
       "                                                     'his', 'himself', 'she',\n",
       "                                                     \"she's\", 'her', 'hers',\n",
       "                                                     'herself', 'it', \"it's\",\n",
       "                                                     'its', 'itself', ...]]},\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(text_train, econ_train) # I run the gridsearch on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bdcf59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\") # I print the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f629621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(text_valid) # I make my predictions with the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8898b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.81      0.84      0.82       250\n",
      "Non-Economic       0.77      0.74      0.75       190\n",
      "\n",
      "    accuracy                           0.79       440\n",
      "   macro avg       0.79      0.79      0.79       440\n",
      "weighted avg       0.79      0.79      0.79       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I print a classification report for the predicted values against the true labels from the validation set.\n",
    "print(metrics.classification_report(econ_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1286f",
   "metadata": {},
   "source": [
    "Thanks to hyper-parameter fine-tuning, the Logistic Regression model attains a level of performance similar to the baseline. The classifier's tendency of artificially inflating the number of positive labels is greatly reduced, with the Non-Economic category's recall sharply increasing from 0.67 to 0.74. The main trade-off concerns how well the model fares in handling the Economic class, with its associated F1 score shrinking from 0.84 to 0.82, but it is acceptable as it helps covering the classifier's greatest weakness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f692c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a. Support Vector Machine classifier with linear kernel and TfIdf Vectorizer\n",
    "\n",
    "pipeline = Pipeline( # Constructing a pipeline comprised of two steps.\n",
    "    steps = [\n",
    "        (\"vectorizer\", TfidfVectorizer()), # A TfIdfVectorizer, without any previously specified parameters.\n",
    "        (\"classifier\", SVC(kernel = \"linear\")), # A Support Vector Machine, with the \"linear\" kernel trick.\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = { # In the gridsearch I want to search for...\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)], # Whether I want to allow for bigrams or tri-grams.\n",
    "    \"vectorizer__stop_words\": [None, stop_words], # Whether I want to remove stopwords or not.\n",
    "    \"vectorizer__max_df\": [0.5, 0.75], # Different cutoffs for the maximum... \n",
    "    \"vectorizer__min_df\": [0, 5, 10], # and minimum thresholds for pruning.\n",
    "    \"classifier__C\": [0.01, 1, 10, 100], # The most optimal regularisation parameter for the Support Vector Machine.\n",
    "}\n",
    "\n",
    "# I run a gridsearch with the standard 5 k-folds, maximising the macro-F1 score since class imbalances are critical within\n",
    "# this classification task.\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = pipeline, n_jobs = -1, param_grid = grid, scoring = \"f1_macro\", cv = 5, verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29d4ac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': [0.01, 1, 10, 100],\n",
       "                         'vectorizer__max_df': [0.5, 0.75],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__stop_words': [None,\n",
       "                                                    ['i', 'me', 'my', 'myself',\n",
       "                                                     'we', 'our', 'ours',\n",
       "                                                     'ourselves', 'you',\n",
       "                                                     \"you're\", \"you've\",\n",
       "                                                     \"you'll\", \"you'd\", 'your',\n",
       "                                                     'yours', 'yourself',\n",
       "                                                     'yourselves', 'he', 'him',\n",
       "                                                     'his', 'himself', 'she',\n",
       "                                                     \"she's\", 'her', 'hers',\n",
       "                                                     'herself', 'it', \"it's\",\n",
       "                                                     'its', 'itself', ...]]},\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(text_train, econ_train) # I run the gridsearch on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "637e7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 1, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\") # I print the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7fc3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(text_valid) # I make my predictions with the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6082f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.81      0.84      0.83       250\n",
      "Non-Economic       0.78      0.74      0.76       190\n",
      "\n",
      "    accuracy                           0.80       440\n",
      "   macro avg       0.79      0.79      0.79       440\n",
      "weighted avg       0.80      0.80      0.80       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I print a classification report for the predicted values against the true labels from the validation set.\n",
    "print(metrics.classification_report(econ_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67b1aa",
   "metadata": {},
   "source": [
    "Never change a winning team they say. It seems there was no need to fine-tune the SVM classifier with the `linear` kernel trick,  which is the best model yet, for three reasons: its tendency to artificially inflate the number of positive labels is slightly lower than the rest of the classifiers'; its accuracy is the highest overall (0.80); its F1 scores for both categories are the highest in general - i.e., respectively, 0.83, and 0.76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91b3680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a. Support Vector Machine classifier with rbf kernel and TfIdf Vectorizer\n",
    "\n",
    "pipeline = Pipeline( # Constructing a pipeline comprised of two steps.\n",
    "    steps = [\n",
    "        (\"vectorizer\", TfidfVectorizer()), # A TfIdfVectorizer, without any previously specified parameters.\n",
    "        (\"classifier\", SVC(kernel = \"rbf\")), # A Support Vector Machine, with the \"rbf\" kernel trick.\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = { # In the gridsearch I want to search for...\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)], # Whether I want to allow for bigrams or tri-grams.\n",
    "    \"vectorizer__stop_words\": [None, stop_words], # Whether I want to remove stopwords or not.\n",
    "    \"vectorizer__max_df\": [0.5, 0.75], # Different cutoffs for the maximum... \n",
    "    \"vectorizer__min_df\": [0, 5, 10], # and minimum thresholds for pruning.\n",
    "    \"classifier__C\": [0.01, 1, 10, 100], # The most optimal regularisation parameter for the Support Vector Machine.\n",
    "}\n",
    "\n",
    "# I run a gridsearch with the standard 5 k-folds, maximising the macro-F1 score since class imbalances are critical within\n",
    "# this classification task.\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = pipeline, n_jobs = -1, param_grid = grid, scoring = \"f1_macro\", cv = 5, verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cf8d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()), (&#x27;classifier&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': [0.01, 1, 10, 100],\n",
       "                         'vectorizer__max_df': [0.5, 0.75],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__stop_words': [None,\n",
       "                                                    ['i', 'me', 'my', 'myself',\n",
       "                                                     'we', 'our', 'ours',\n",
       "                                                     'ourselves', 'you',\n",
       "                                                     \"you're\", \"you've\",\n",
       "                                                     \"you'll\", \"you'd\", 'your',\n",
       "                                                     'yours', 'yourself',\n",
       "                                                     'yourselves', 'he', 'him',\n",
       "                                                     'his', 'himself', 'she',\n",
       "                                                     \"she's\", 'her', 'hers',\n",
       "                                                     'herself', 'it', \"it's\",\n",
       "                                                     'its', 'itself', ...]]},\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(text_train, econ_train) # I run the gridsearch on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "159ec45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 1, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': None}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\") # I print the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09c768e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(text_valid) # I make my predictions with the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7962fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.78      0.86      0.82       250\n",
      "Non-Economic       0.79      0.68      0.73       190\n",
      "\n",
      "    accuracy                           0.79       440\n",
      "   macro avg       0.79      0.77      0.78       440\n",
      "weighted avg       0.79      0.79      0.78       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I print a classification report for the predicted values against the true labels from the validation set.\n",
    "print(metrics.classification_report(econ_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2981e54",
   "metadata": {},
   "source": [
    "Again, never change a winning team. Trying to gear hyperparameters towards the maximum macro-F1 score actually yields worse fit on the validation set, which leads me to instantly discard the SVM classifier with the `rbf` kernel trick. In the end, the best choice for the Economic / Non-Economic classification task is the **SVM classifier with the `linear` kernel trick and the `TfIdfVectorizer`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93d1083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Socio-Cultural / Non-Socio-Cultural\n",
    "\n",
    "# 1b. Naive-Bayes classifier with CountVectorizer\n",
    "\n",
    "pipeline = Pipeline( # Constructing a pipeline comprised of two steps.\n",
    "    steps = [\n",
    "        (\"vectorizer\", CountVectorizer()), # A CountVectorizer, without any previously specified parameters.\n",
    "        (\"classifier\", MultinomialNB()), # A Multinomial Naive-Bayes, without any previously specified parameters.\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = { # In the gridsearch I want to search for...\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)], # Whether I want to allow for bigrams or tri-grams.\n",
    "    \"vectorizer__stop_words\": [None, stop_words], # Whether I want to remove English stopwords or not.\n",
    "    \"vectorizer__max_df\": [0.5, 0.75], # Different cutoffs for the maximum... \n",
    "    \"vectorizer__min_df\": [0, 5, 10], # and minimum thresholds for pruning.\n",
    "    \"classifier__alpha\": [0.01, 1, 10, 100], # The most optimal alpha for the Naive-Bayes\n",
    "}\n",
    "\n",
    "# I run a gridsearch with the standard 5 k-folds, maximising the macro-F1 score since class imbalances are critical within\n",
    "# this classification task.\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = pipeline, n_jobs = -1, param_grid = grid, scoring = \"f1_macro\", cv = 5, verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a83658bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__alpha&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__alpha&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__alpha': [0.01, 1, 10, 100],\n",
       "                         'vectorizer__max_df': [0.5, 0.75],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__stop_words': [None,\n",
       "                                                    ['i', 'me', 'my', 'myself',\n",
       "                                                     'we', 'our', 'ours',\n",
       "                                                     'ourselves', 'you',\n",
       "                                                     \"you're\", \"you've\",\n",
       "                                                     \"you'll\", \"you'd\", 'your',\n",
       "                                                     'yours', 'yourself',\n",
       "                                                     'yourselves', 'he', 'him',\n",
       "                                                     'his', 'himself', 'she',\n",
       "                                                     \"she's\", 'her', 'hers',\n",
       "                                                     'herself', 'it', \"it's\",\n",
       "                                                     'its', 'itself', ...]]},\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(text_train, sc_train) # I run the gridsearch on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a25a9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__alpha': 1, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\") # I print the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11ea6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(text_valid) # I make my predictions with the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3d24a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.80      0.71      0.76       178\n",
      "    Socio-Cultural       0.82      0.88      0.85       262\n",
      "\n",
      "          accuracy                           0.81       440\n",
      "         macro avg       0.81      0.80      0.80       440\n",
      "      weighted avg       0.81      0.81      0.81       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I print a classification report for the predicted values against the true labels from the validation set.\n",
    "print(metrics.classification_report(sc_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c4fbe",
   "metadata": {},
   "source": [
    "I will not repeat myself for a third time, as I would be overusing an objectively unfunny line. Again, there is no remarkable change from the original Naive-Bayes classifier with the `CountVectorizer`, so this remains the model that exhibits the lesser tendency of artificially inflating the number of positive labels, while retaining the highest overall accuracy (0.81)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49307d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Support Vector Machine classifier with linear kernel and TfIdf Vectorizer\n",
    "\n",
    "pipeline = Pipeline( # Constructing a pipeline comprised of two steps.\n",
    "    steps = [\n",
    "        (\"vectorizer\", TfidfVectorizer()), # A TfIdfVectorizer, without any previously specified parameters.\n",
    "        (\"classifier\", SVC(kernel = \"linear\")), # A Support Vector Machine, with the \"linear\" kernel trick.\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = { # In the gridsearch I want to search for...\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)], # Whether I want to allow for bigrams or tri-grams.\n",
    "    \"vectorizer__stop_words\": [None, stop_words], # Whether I want to remove stopwords or not.\n",
    "    \"vectorizer__max_df\": [0.5, 0.75], # Different cutoffs for the maximum... \n",
    "    \"vectorizer__min_df\": [0, 5, 10], # and minimum thresholds for pruning.\n",
    "    \"classifier__C\": [0.01, 1, 10, 100], # The most optimal regularisation parameter for the Support Vector Machine.\n",
    "}\n",
    "\n",
    "# I run a gridsearch with the standard 5 k-folds, maximising the macro-F1 score since class imbalances are critical within\n",
    "# this classification task.\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = pipeline, n_jobs = -1, param_grid = grid, scoring = \"f1_macro\", cv = 5, verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dd30dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 1, 10, 100],\n",
       "                         &#x27;vectorizer__max_df&#x27;: [0.5, 0.75],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 5, 10],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)],\n",
       "                         &#x27;vectorizer__stop_words&#x27;: [None,\n",
       "                                                    [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;,\n",
       "                                                     &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                     &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                     &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                     &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                     &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                     &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                     &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                     &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                     &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                     &#x27;its&#x27;, &#x27;itself&#x27;, ...]]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': [0.01, 1, 10, 100],\n",
       "                         'vectorizer__max_df': [0.5, 0.75],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__stop_words': [None,\n",
       "                                                    ['i', 'me', 'my', 'myself',\n",
       "                                                     'we', 'our', 'ours',\n",
       "                                                     'ourselves', 'you',\n",
       "                                                     \"you're\", \"you've\",\n",
       "                                                     \"you'll\", \"you'd\", 'your',\n",
       "                                                     'yours', 'yourself',\n",
       "                                                     'yourselves', 'he', 'him',\n",
       "                                                     'his', 'himself', 'she',\n",
       "                                                     \"she's\", 'her', 'hers',\n",
       "                                                     'herself', 'it', \"it's\",\n",
       "                                                     'its', 'itself', ...]]},\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(text_train, sc_train) # I run the gridsearch on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "149b4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 10, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3), 'vectorizer__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\") # I print the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6662760",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(text_valid) # I make my predictions with the best parameters found by the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4153ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.82      0.66      0.73       178\n",
      "    Socio-Cultural       0.80      0.90      0.85       262\n",
      "\n",
      "          accuracy                           0.80       440\n",
      "         macro avg       0.81      0.78      0.79       440\n",
      "      weighted avg       0.81      0.80      0.80       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I print a classification report for the predicted values against the true labels from the validation set.\n",
    "print(metrics.classification_report(sc_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bb44e",
   "metadata": {},
   "source": [
    "Fine-tuning hyperparameters of the SVM classifier with the `linear` kernel trick and the `TfIdfVectorizer` leads to way more promising performance metrics all across the board. However, the overall accuracy is still worse than the fine-tuned baseline - i.e., 0.81 (NB) versus 0.80 (SVM) - and the same is true for the Non-Socio-Cultural category's recall - i.e., 0.71 (NB) versus 0.66 (SVM). This implies that this alternative model is actually more inclined to artificially inflate the number of positive labels, leading me to discard it. In the end, the best choice for the Socio-Cultural / Non-Socio-Cultural classification task is what should have been the baseline - i.e., the **Naive-Bayes classifier with the `CountVectorizer`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c57088",
   "metadata": {},
   "source": [
    "## 5. The Final Tests\n",
    "\n",
    "To account for the two selected classifiers' potential overfitting of the validation data, I run two separate final evaluations on the unseen testing set I kept aside from the start. First, I check the **SVM classifier with the `linear` kernel trick and the `TfIdfVectorizer`**, geared towards the Economic / Non-Economic classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eef9bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, kernel='linear')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Economic / Non-Economic\n",
    "\n",
    "# I define the optimised TfIdfVectorizer with the fine-tuned hyperparameters found by the gridsearch...\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1, 1), min_df = 0, max_df = .75)\n",
    "\n",
    "# ...and I do the same with the SVM classifier.\n",
    "classifier = SVC(kernel = \"linear\", C = 10)\n",
    "\n",
    "# I generate the BOW feature representation by fitting the vectorizer on my training data...\n",
    "x_train = vectorizer.fit_transform(text_train)\n",
    "\n",
    "# ...and testing data.\n",
    "x_test = vectorizer.transform(text_test)\n",
    "\n",
    "# I now train my optimised classifier.\n",
    "classifier.fit(x_train, econ_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9996099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Economic       0.78      0.76      0.77       222\n",
      "Non-Economic       0.76      0.78      0.77       218\n",
      "\n",
      "    accuracy                           0.77       440\n",
      "   macro avg       0.77      0.77      0.77       440\n",
      "weighted avg       0.77      0.77      0.77       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I make my predictions on the yet unseen set for testing purposes...\n",
    "pred = classifier.predict(x_test)\n",
    "\n",
    "# ...and I print a classification report for the predicted values against the true labels from the test database.\n",
    "print(metrics.classification_report(econ_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc5a13",
   "metadata": {},
   "source": [
    "Unfortunately, it appears that randomisation has dealt me an unlucky hand. The negative category is non-negligibly overrepresented in the Economic / Non-Economic label test set, which means that this classification report should be interpreted with added caution. Its overall performance is slightly diminished, partially due to overfitting of the validation set, but the **SVM classifier with the `linear` kernel trick and the `TfIdfVectorizer`** is still a great model for solving this classification task. Although the figures should be taken with a grain of salt, in this particular instance the classifier shows solid metrics all across the board, which is very valuable since the most common issue throughout the pipeline has been artificial inflating of the positive labels. \n",
    "\n",
    "Before turning to the Socio-Cultural / Non-Socio-Cultural classification task, I save this vectorizer and classifier combination in two compressed files. This allows me to load the summary classifier I just trained at any given moment without needing to re-estimate it. Information on the performance optimisation provided by the `joblib` library (instead of the usual `pickle` library) was inspired by `ogrisel`'s top-rated response to the https://stackoverflow.com/questions/12615525/what-are-the-different-use-cases-of-joblib-versus-pickle thread. I must greatly thank this user for helping me to fine-tune my code, even though the performance gain is not too relevant for my application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1831ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now save the vectorizer and the classifier as compressed files.\n",
    "# I employ the joblib library, which is faster than pickle in saving or loading large NumPy arrays.\n",
    "\n",
    "with open(\"econ_vectorizer.pkl\", mode = \"wb\") as f:\n",
    "    joblib.dump(vectorizer, f)\n",
    "    \n",
    "with open(\"econ_classifier.pkl\", mode = \"wb\") as f:\n",
    "    joblib.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d91e8847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Socio-Cultural / Non-Socio-Cultural\n",
    "\n",
    "# I define the optimised CountVectorizer with the fine-tuned hyperparameters found by the gridsearch...\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 1), min_df = 0, max_df = .5, stop_words = stop_words)\n",
    "\n",
    "# ...and I do the same with the NB classifier.\n",
    "classifier = MultinomialNB(alpha = 1)\n",
    "\n",
    "# I generate the BOW feature representation by fitting the vectorizer on my training data...\n",
    "x_train = vectorizer.fit_transform(text_train)\n",
    "\n",
    "# ...and testing data.\n",
    "x_test = vectorizer.transform(text_test)\n",
    "\n",
    "# I now train my optimised classifier.\n",
    "classifier.fit(x_train, sc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45d0d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Socio-Cultural       0.77      0.71      0.74       157\n",
      "    Socio-Cultural       0.84      0.88      0.86       283\n",
      "\n",
      "          accuracy                           0.82       440\n",
      "         macro avg       0.81      0.80      0.80       440\n",
      "      weighted avg       0.82      0.82      0.82       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I make my predictions on the yet unseen set for testing purposes...\n",
    "pred = classifier.predict(x_test)\n",
    "\n",
    "# ...and I print a classification report for the predicted values against the true labels from the test database.\n",
    "print(metrics.classification_report(sc_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e052b37",
   "metadata": {},
   "source": [
    "On the other hand, the **Naive-Bayes classifier with the `CountVectorizer`** retains most of its performance even when applied to the test set. There is a slight accuracy drop, from 0.82 to 0.81, mostly provoked by the precision loss concerning the Non-Socio-Cultural category, but the classifier is an acceptable answer to the Socio-Cultural / Non-Socio-Cultural classification task. However, there is a bitter note at the end, as the recall metrics still imply that there is an underlying bias towards the positive label. This recurring problem is likely caused by how conceptually broad and abstract the categories I employed for human annotation are, and it points to the need of transcending the Bag-Of-Words approach to take context into account.\n",
    "\n",
    "I still decide to save this vectorizer and classifier combination in two compressed files, just in case the state-of-the-art BERT fine-tuning technique does not lead to better outcomes. This allows me to load the summary classifier I just trained at any given moment without needing to re-estimate it. Information on the performance optimisation provided by the `joblib` library (instead of the usual `pickle` library) was inspired by `ogrisel`'s top-rated response to the https://stackoverflow.com/questions/12615525/what-are-the-different-use-cases-of-joblib-versus-pickle thread. I must greatly thank this user for helping me to fine-tune my code, even though the performance gain is not too relevant for my application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ce20fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now save the vectorizer and the classifier as compressed files.\n",
    "# I employ the joblib library, which is faster than pickle in saving or loading large NumPy arrays.\n",
    "\n",
    "with open(\"sc_vectorizer.pkl\", mode = \"wb\") as f:\n",
    "    joblib.dump(vectorizer, f)\n",
    "    \n",
    "with open(\"sc_classifier.pkl\", mode = \"wb\") as f:\n",
    "    joblib.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d9a83",
   "metadata": {},
   "source": [
    "## 6. Wrapping Up\n",
    "\n",
    "The vectorizer + classifier combinations I fine-tuned with grid-searches could be greatly improved. Even though the accuracy of the respective solutions hovers around the 80% mark, which is pretty satisfactory, there is a recurring and underlying bias towards the positive labels. The most flexible and powerful solution to transcend the Bag-Of-Words approach and try solving this issue is to fine-tune a BERT transformer specifically trained on legal text in English, to ensure that the pre-training phase is consistent with my domain of interest - i.e., US Congress bills. However, this necessitates a great deal of supplementary computational effort, to the extent that I am forced to load my script on Google CoLab, in order to employ Google's GPUs.\n",
    "\n",
    "Thus, I will download the pre-trained `nlpaueb/legal-bert-base-uncased`, a BERT model from the `HuggingFace` library, created by the Athens University of Economics and Business's Natural Language Processing Group. The LEGAL-BERT model is pre-trained on a corpora of EU legislation, UK legislation, US contracts from the US Securities and Exchange Commission (SECOM), and cases from the European Court of Justice (ECJ), European Court of Human Rights (ECHR), and various courts across the USA. It is available at https://huggingface.co/nlpaueb/legal-bert-base-uncased. I expect that by fine-tuning this transformer for my specific downstream tasks will lead to superior performances in both classification tasks, ultimately yielding more nuanced predictions that take context and temporality into account."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
